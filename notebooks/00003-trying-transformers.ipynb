{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recibrew.data_util import construct_torchtext_iterator\n",
    "train_csv = '../data/processed/train.csv'\n",
    "dev_csv = '../data/processed/dev.csv'\n",
    "test_csv = '../data/processed/test.csv'\n",
    "constructed_ttext = construct_torchtext_iterator(train_csv, dev_csv, test_csv, device='cpu', fix_length=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_iter', 'val_iter', 'test_iter', 'src_field', 'tgt_field'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constructed_ttext.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = constructed_ttext['train_iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_field = constructed_ttext['src_field']\n",
    "tgt_field = constructed_ttext['tgt_field']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vocab = len(src_field.vocab)\n",
    "max_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "btch = next(train_iter.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt = btch.src, btch.tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer, Embedding, Dropout, Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfm = Transformer(d_model=128, dim_feedforward=512, num_encoder_layers=4, num_decoder_layers=4, dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embedding = 128\n",
    "dropout = 0.2\n",
    "max_len = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_emb_dec = pos_embedding(inp_embedding(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 128])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_emb_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([121, 64, 128])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_emb_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullTransformer(Module):\n",
    "    \n",
    "    def __init__(self, num_embedding=128, dim_feedforward=512, num_encoder_layer=4, num_decoder_layer=4, dropout=0.3, padding_idx=1):\n",
    "        super(FullTransformer, self).__init__()\n",
    "        \n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        # [x : seq_len,  batch_size ]\n",
    "        self.inp_embedding = Embedding(max_vocab , num_embedding, padding_idx=padding_idx)\n",
    "\n",
    "        # [ x : seq_len, batch_size, num_embedding ]\n",
    "        self.pos_embedding = PositionalEncoding(num_embedding, dropout, max_len=max_len)\n",
    "        \n",
    "        self.trfm = Transformer(d_model=num_embedding, dim_feedforward=dim_feedforward, \n",
    "                                num_encoder_layers=num_encoder_layer, num_decoder_layers=num_decoder_layer, \n",
    "                                dropout=dropout)\n",
    "    \n",
    "    def make_pad_mask(self, inp):\n",
    "        \"\"\"\n",
    "        Make mask attention that caused 'True' element will not be attended (ignored).\n",
    "        Padding stated in self.padding_idx will not be attended at all.\n",
    "        \"\"\"\n",
    "        return (inp == self.padding_idx).transpose(0, 1)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        forward!\n",
    "        \"\"\"\n",
    "        # Generate mask for decoder attention\n",
    "        tgt_mask = ft.trfm.generate_square_subsequent_mask(len(tgt))   \n",
    "        \n",
    "        # trg_mask shape = [target_seq_len, target_seq_len]\n",
    "        src_pad_mask = self.make_pad_mask(src)\n",
    "        tgt_pad_mask = self.make_pad_mask(tgt)\n",
    "        \n",
    "        # [ src : seq_len, batch_size, num_embedding ]\n",
    "\n",
    "        out_emb_enc = self.pos_embedding(inp_embedding(src))\n",
    "        \n",
    "        # [ src : seq_len, batch_size, num_embedding ]\n",
    "        out_emb_dec = self.pos_embedding(inp_embedding(tgt))\n",
    "        \n",
    "        out_trf = self.trfm(out_emb_enc, out_emb_dec, src_mask=None, tgt_mask=tgt_mask, memory_mask=None,\n",
    "                          src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        # [ out_trf : seq_len, batch_size, num_embedding]\n",
    "        return out_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FullTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ x : seq_len, batch_size, num_embedding ]\n",
    "\n",
    "out_emb_enc = ft.pos_embedding(ft.inp_embedding(src))\n",
    "out_emb_dec = ft.pos_embedding(ft.inp_embedding(tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
       "        [  5,   6,   5,  ...,   6,   5,   5],\n",
       "        [ 16, 225, 114,  ..., 193,  16,  93],\n",
       "        ...,\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1],\n",
       "        [  1,   1,   1,  ...,   1,   1,   1]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_trf = ft(src,tgt[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_truth = tgt[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_mask = ft.trfm.generate_square_subsequent_mask(len(tgt))  # Mask for generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.forward(src, tgt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6885,  0.3914, -0.1431,  ..., -2.0010, -2.1248,  1.2258],\n",
       "         [-0.8926,  0.4760,  0.0989,  ..., -1.8607, -1.8448, -0.6924],\n",
       "         [-0.7496,  1.6615,  0.3059,  ..., -1.6595, -2.5151, -1.3831],\n",
       "         ...,\n",
       "         [-1.8085,  1.0539, -0.6407,  ..., -1.0351, -1.2879, -1.1842],\n",
       "         [-0.5450,  1.0887, -0.3561,  ..., -0.5517, -2.0140, -1.0108],\n",
       "         [-1.0373,  1.8606,  1.2161,  ..., -0.6123, -2.4126, -0.0155]],\n",
       "\n",
       "        [[-0.5035,  0.7363,  1.6802,  ..., -1.0266, -1.4050, -0.6545],\n",
       "         [-0.6525, -0.1513, -0.5397,  ..., -0.1573, -2.2122, -0.4740],\n",
       "         [-1.3595,  0.4303, -0.4063,  ..., -0.6392, -0.9940, -1.8435],\n",
       "         ...,\n",
       "         [-0.8114, -1.2614, -0.2073,  ..., -1.0146, -0.2468,  0.0290],\n",
       "         [-2.1922,  0.4243,  1.3759,  ..., -0.9851, -1.4986, -1.1615],\n",
       "         [-0.9675, -1.4978, -1.0785,  ..., -0.3849, -1.1353, -0.1319]],\n",
       "\n",
       "        [[-0.2701,  0.3993,  0.7897,  ..., -2.2512, -0.6533,  0.2493],\n",
       "         [-2.8280,  0.7702,  0.4581,  ...,  0.3264, -1.6351, -2.7073],\n",
       "         [ 0.8151,  0.9308, -0.1211,  ..., -0.9137, -2.1176,  0.3126],\n",
       "         ...,\n",
       "         [-0.5127,  1.3821,  0.9630,  ..., -0.5301, -2.8765, -0.0896],\n",
       "         [ 0.4862,  1.1183,  0.0745,  ..., -0.6099, -2.5082, -1.3788],\n",
       "         [-0.6723,  0.5220, -0.1735,  ..., -0.2726, -2.1370, -0.2028]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2201, -0.5176, -0.0470,  ..., -1.7740, -0.1507, -1.1312],\n",
       "         [-1.0180,  0.3810, -0.8740,  ..., -0.1745, -2.7059, -0.6363],\n",
       "         [-1.7654, -1.9290, -0.4211,  ..., -0.7304, -2.4334, -1.2015],\n",
       "         ...,\n",
       "         [-1.2988,  1.3866,  0.5069,  ..., -1.4561, -0.6614,  0.0520],\n",
       "         [-1.0816,  0.4689,  1.0756,  ..., -1.0079, -1.1809, -0.5774],\n",
       "         [-0.6440, -0.6838, -0.8311,  ..., -0.8225, -1.7412, -0.9398]],\n",
       "\n",
       "        [[-0.8650,  0.1922, -0.1218,  ...,  0.5671, -2.7675, -0.2978],\n",
       "         [-0.2037, -0.1875, -1.4786,  ..., -0.4213, -0.3752, -0.6815],\n",
       "         [-1.4894,  0.2872,  0.2882,  ..., -0.0683, -0.7966, -1.3619],\n",
       "         ...,\n",
       "         [-1.1686, -0.6882,  0.5286,  ...,  0.0347, -3.8066, -0.1807],\n",
       "         [-0.9253, -0.1330,  0.7394,  ..., -0.8829, -1.8569, -1.4583],\n",
       "         [-0.2262,  0.3953, -0.6451,  ..., -1.1709, -1.8670, -0.8179]],\n",
       "\n",
       "        [[-0.2630,  0.6391,  0.1044,  ..., -0.2959, -1.3019, -0.2494],\n",
       "         [-1.1345,  0.5297,  0.1716,  ..., -0.8535, -2.3707, -0.1065],\n",
       "         [-0.8728,  1.0960, -0.3246,  ..., -2.3425, -1.7156,  0.4234],\n",
       "         ...,\n",
       "         [-1.4697, -1.3196, -0.5714,  ...,  0.1067, -0.6679, -1.1855],\n",
       "         [-0.2729,  1.1420,  0.4589,  ..., -0.3771, -2.4497,  0.0191],\n",
       "         [-0.6499,  0.0827,  0.1779,  ..., -0.3265, -2.4510,  0.1943]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trfm.forward(out_emb_enc, out_emb_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 3004])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_to_out(reformer_out[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine them to become a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recibrew.nn.transformers import FullTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FullTransformer(max_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_trf = ft.forward(src, tgt[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 64, 3004])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_trf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 64, 3004])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_trf.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 64])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7680])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[1:].view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180240, 128])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_trf.view(-1, output_dim).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 64, 3004])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_trf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = out_trf.shape[-1]\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1723, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(out_trf.view(-1, output_dim), tgt[1:,:].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected target size (120, 128), got torch.Size([120, 64])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-5ece0c212bca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_trf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\recibrew\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2122\u001b[0m         \u001b[0mout_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2124\u001b[1;33m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0m\u001b[0;32m   2125\u001b[0m                 out_size, target.size()))\n\u001b[0;32m   2126\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected target size (120, 128), got torch.Size([120, 64])"
     ]
    }
   ],
   "source": [
    "F.nll_loss(out_trf, tgt[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
